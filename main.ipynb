{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on CPU\n",
      "running on CPU\n"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "from demo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14006c710>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random seed\n",
    "manualSeed = 1\n",
    "\n",
    "np.random.seed(manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 6, 35, 35, 4)\n"
     ]
    }
   ],
   "source": [
    "# 120 samples and 6 timepoints.\n",
    "X = prepare_data(new_data=True,n_samples=120,n_times=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X)\n",
    "X = X.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = np.zeros((args.num_folds - 1, args.num_timepoints))\n",
    "table = random_table(args, 4/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 1. 0.]\n",
      " [1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/5]-----------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "Ordering of the hospitals:  [3 2 1 0]\n",
      "Epoch [1/60]\n",
      "Hospital [4/4]\n",
      "[Train] Loss T1: 1.22179 [Train] TP Loss T1: 1029.44795  [Train] Total Loss T1: 5147.85060 \n",
      "Hospital [3/4]\n",
      "[Train] Loss T1: 1.24068 [Train] TP Loss T1: 1074.96619  [Train] Total Loss T1: 5375.45127 \n",
      "Hospital [2/4]\n",
      "[Train] Loss T1: 1.29457 [Train] TP Loss T1: 1228.35232  [Train] Total Loss T1: 6142.40892 \n",
      "Hospital [1/4]\n",
      "[Train] Loss T1: 0.62551 [Train] TP Loss T1: 563.35402  [Train] Total Loss T1: 5634.16562 \n",
      "Epoch [2/60]\n",
      "Hospital [4/4]\n",
      "[Train] Loss T1: 0.36086 [Train] TP Loss T1: 87.08272  [Train] Total Loss T1: 435.59401 \n",
      "Hospital [3/4]\n",
      "[Train] Loss T1: 0.35700 [Train] TP Loss T1: 84.09768  [Train] Total Loss T1: 420.66691 \n",
      "Hospital [2/4]\n",
      "[Train] Loss T1: 0.34148 [Train] TP Loss T1: 77.80627  [Train] Total Loss T1: 389.20208 \n",
      "Hospital [1/4]\n",
      "[Train] Loss T1: 0.18854 [Train] TP Loss T1: 47.30852  [Train] Total Loss T1: 473.27371 \n",
      "Epoch [3/60]\n",
      "Hospital [4/4]\n",
      "[Train] Loss T1: 0.29154 [Train] TP Loss T1: 56.70552  [Train] Total Loss T1: 283.67336 \n",
      "Hospital [3/4]\n",
      "[Train] Loss T1: 0.28021 [Train] TP Loss T1: 51.47773  [Train] Total Loss T1: 257.52878 \n",
      "Hospital [2/4]\n",
      "[Train] Loss T1: 0.27401 [Train] TP Loss T1: 48.84038  [Train] Total Loss T1: 244.33892 \n",
      "Hospital [1/4]\n",
      "[Train] Loss T1: 0.14604 [Train] TP Loss T1: 27.99827  [Train] Total Loss T1: 280.12871 \n",
      "Epoch [4/60]\n",
      "Hospital [4/4]\n",
      "[Train] Loss T1: 0.25796 [Train] TP Loss T1: 44.45651  [Train] Total Loss T1: 222.41153 \n",
      "Hospital [3/4]\n",
      "[Train] Loss T1: 0.23994 [Train] TP Loss T1: 37.95941  [Train] Total Loss T1: 189.91702 \n",
      "Hospital [2/4]\n",
      "[Train] Loss T1: 0.24448 [Train] TP Loss T1: 39.01845  [Train] Total Loss T1: 195.21448 \n",
      "Hospital [1/4]\n",
      "[Train] Loss T1: 0.12938 [Train] TP Loss T1: 22.03031  [Train] Total Loss T1: 220.43247 \n",
      "Epoch [5/60]\n",
      "Hospital [4/4]\n",
      "[Train] Loss T1: 0.23394 [Train] TP Loss T1: 36.42366  [Train] Total Loss T1: 182.23525 \n",
      "Hospital [3/4]\n",
      "[Train] Loss T1: 0.22350 [Train] TP Loss T1: 32.97576  [Train] Total Loss T1: 164.99057 \n",
      "Hospital [2/4]\n",
      "[Train] Loss T1: 0.22764 [Train] TP Loss T1: 33.96656  [Train] Total Loss T1: 169.94661 \n",
      "Hospital [1/4]\n",
      "[Train] Loss T1: 0.11840 [Train] TP Loss T1: 18.50534  [Train] Total Loss T1: 185.17182 \n",
      "Epoch [6/60]\n",
      "Hospital [4/4]\n",
      "[Train] Loss T1: 0.21746 [Train] TP Loss T1: 31.46050  [Train] Total Loss T1: 157.41122 \n",
      "Hospital [3/4]\n",
      "[Train] Loss T1: 0.20641 [Train] TP Loss T1: 28.12866  [Train] Total Loss T1: 140.74649 \n",
      "Hospital [2/4]\n",
      "[Train] Loss T1: 0.21176 [Train] TP Loss T1: 29.44033  [Train] Total Loss T1: 147.30755 \n",
      "Hospital [1/4]\n",
      "[Train] Loss T1: 0.10924 [Train] TP Loss T1: 15.76630  [Train] Total Loss T1: 157.77221 \n",
      "Epoch [7/60]\n",
      "Hospital [4/4]\n",
      "[Train] Loss T1: 0.20250 [Train] TP Loss T1: 27.25201  [Train] Total Loss T1: 136.36131 \n",
      "Hospital [3/4]\n",
      "[Train] Loss T1: 0.19332 [Train] TP Loss T1: 24.60329  [Train] Total Loss T1: 123.11311 \n",
      "Hospital [2/4]\n",
      "[Train] Loss T1: 0.19892 [Train] TP Loss T1: 25.99724  [Train] Total Loss T1: 130.08564 \n",
      "Hospital [1/4]\n",
      "[Train] Loss T1: 0.10002 [Train] TP Loss T1: 13.27285  [Train] Total Loss T1: 132.82852 \n",
      "Epoch [8/60]\n",
      "Hospital [4/4]\n",
      "[Train] Loss T1: 0.18797 [Train] TP Loss T1: 23.43942  [Train] Total Loss T1: 117.29109 \n",
      "Hospital [3/4]\n",
      "[Train] Loss T1: 0.18043 [Train] TP Loss T1: 21.35573  [Train] Total Loss T1: 106.86889 \n",
      "Hospital [2/4]\n",
      "[Train] Loss T1: 0.18688 [Train] TP Loss T1: 22.93094  [Train] Total Loss T1: 114.74813 \n",
      "Hospital [1/4]\n",
      "[Train] Loss T1: 0.09268 [Train] TP Loss T1: 11.40397  [Train] Total Loss T1: 114.13235 \n",
      "Epoch [9/60]\n",
      "Hospital [4/4]\n",
      "[Train] Loss T1: 0.19183 [Train] TP Loss T1: 24.66414  [Train] Total Loss T1: 123.41663 \n",
      "Hospital [3/4]\n",
      "[Train] Loss T1: 0.18167 [Train] TP Loss T1: 21.77561  [Train] Total Loss T1: 108.96887 \n",
      "Hospital [2/4]\n",
      "[Train] Loss T1: 0.18765 [Train] TP Loss T1: 23.26934  [Train] Total Loss T1: 116.44054 \n",
      "Hospital [1/4]\n",
      "[Train] Loss T1: 0.10649 [Train] TP Loss T1: 15.07534  [Train] Total Loss T1: 150.85990 \n",
      "Epoch [10/60]\n",
      "Hospital [4/4]\n",
      "[Train] Loss T1: 0.17344 [Train] TP Loss T1: 20.19501  [Train] Total Loss T1: 101.06175 \n",
      "Hospital [3/4]\n",
      "[Train] Loss T1: 0.16654 [Train] TP Loss T1: 18.19508  [Train] Total Loss T1: 91.05865 \n",
      "Hospital [2/4]\n",
      "[Train] Loss T1: 0.17035 [Train] TP Loss T1: 19.04431  [Train] Total Loss T1: 95.30673 \n",
      "Hospital [1/4]\n",
      "[Train] Loss T1: 0.09709 [Train] TP Loss T1: 12.64019  [Train] Total Loss T1: 126.49901 \n",
      "Epoch [11/60]\n",
      "Hospital [4/4]\n",
      "[Train] Loss T1: 0.15907 [Train] TP Loss T1: 16.80688  [Train] Total Loss T1: 84.11394 \n",
      "Hospital [3/4]\n",
      "[Train] Loss T1: 0.15260 [Train] TP Loss T1: 15.04926  [Train] Total Loss T1: 75.32259 \n",
      "Hospital [2/4]\n",
      "[Train] Loss T1: 0.15769 [Train] TP Loss T1: 16.15534  [Train] Total Loss T1: 80.85554 \n",
      "Hospital [1/4]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Python_Projects/Imperial/Dissertation/Code/4D-FedGNN-Plus_mine/demo.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args, dataset, table)\u001b[0m\n\u001b[1;32m    179\u001b[0m train_data \u001b[39m=\u001b[39m train_data_list[h_i]\n\u001b[1;32m    180\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mHospital [\u001b[39m\u001b[39m{\u001b[39;00mh_i\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(hospitals)\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m hospitals[h_i], tot_l, tp_l, mae_l \u001b[39m=\u001b[39m train_one_epoch(args, h, train_data, f, table, [h_i, t])\n\u001b[1;32m    182\u001b[0m tot_mae \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m mae_l\n\u001b[1;32m    183\u001b[0m tot \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tot_l\n",
      "File \u001b[0;32m~/Desktop/Python_Projects/Imperial/Dissertation/Code/4D-FedGNN-Plus_mine/demo.py:390\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(args, hospital, train_data, fold, table, index)\u001b[0m\n\u001b[1;32m    388\u001b[0m         total_loss \u001b[39m=\u001b[39m loss \u001b[39m+\u001b[39m args\u001b[39m.\u001b[39mtp_coef \u001b[39m*\u001b[39m tp_l\n\u001b[1;32m    389\u001b[0m         tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m total_loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m--> 390\u001b[0m         total_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    391\u001b[0m         hospital\u001b[39m.\u001b[39moptimizers[cur_id]\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    393\u001b[0m \u001b[39melif\u001b[39;00m table[index[\u001b[39m0\u001b[39m], index[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m table[index[\u001b[39m0\u001b[39m], index[\u001b[39m1\u001b[39m]] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    394\u001b[0m     \u001b[39m# if the hospital doesn't have data at current timepoint\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/diss/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args,X[:, :, :, :, 0], table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('diss')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
